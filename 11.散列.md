#11.散列

##11.1 基本数据类型散列
对于**byte**,**short**,**int**和**char**这些基本类型数据，统一转为int类型，并把这个数值当做**散列值**。而对于**float**类型，则采用`Float.floatToIntBits(key)`的返回值作为散列值（该函数返回的int类型的二进制表示跟该float类型的二进制表示是一样的）。

对于**long**类型数据，最简单的做法是采用低4字节作为散列值，但long类型占有8字节数据，此种做法很容易引起**散列碰撞**，最好的做法是：
```Java
int hashCode = (int)(key^(key>>32));
```
将原来的key右移32位并与原来的key做**按位异或**操作，取低4字节作为散列值，这样long类型的高4字节和低4字节都参与了散列值的计算，大大降低了碰撞的概率。

而对应**double**类型数据，首先将key转为double表示（Double.doubleToLongBits(key)）,剩下的跟long的散列值一致：

```Java
long longkey = Double.doubleToLongBits(key);
int hashCode = (int)(longkey^(longkey>>32));
```

###11.1.3 String类型散列
由于String经常被作为key，所以设计一个好的String散列函数是非常重要的。最直接的做法就是获取字符串的每个字符的Unicode编码，并将这些数值相加：
```Java
int hashCode = 0;
for(int i=0; str.length; i++) {
    hashCode += str.charAt(i);
}
```
这种做法计算散列值十分快，每个字符也参与了计算，但是碰撞的概率也非常大，例如bat和atb的散列值是一样的。为了减少碰撞，我们可以让每个字符的位置参与计算：
```
s[0]*b^(n-1) + s[1]*b^(n-2) + ... + s[n-1]
```
为了方便计算，这个多项式可以简化为：
```
(...((s[0]*b + s[1])b + ... + s[n-2])b + s[n-1]
```
在计算过程中，多项式难免越界，我们可以将其忽略，只取低32位的二级制位作为散列值，而同时为了减少碰撞，**b**最好为质数，且为了减少越界和计算量，这个质数通常不能取的太大（但不能过小），实验证明**31**, **33**, **37**, **39**, and **41**都是不错的选择。

以下是JDK的`String.hashCode`方式实现：
```Java
public int hashCode() {
    int h = hash;
    if (h == 0 && value.length > 0) {
        char val[] = value;

        for (int i = 0; i < value.length; i++) {
            h = 31 * h + val[i];
        }
        hash = h;
    }
    return h;
}
```

##11.2 压缩散列码
散列值通常都会比存储数据的数组要大的多，所以，我们需要将散列值压缩至数组的下标范围内。假设数组的大小为N，下标范围为0至N-1，最常用的压缩方法就是使用**求余法**：
```
h(hashCode) = hashCode % N;
```
为了散列均匀分布，在理想情况下，**N**最好是一个质数。然而寻找质数本身就是一个非常消耗性能的操作。在Java API中的HashMap里，N的取值为**2的指数（the power of 2）**。这样的好处在于：当N为2的指数时，以下两个操作是等价的：
```
h(hashCode) = hashCode % N;   等价于  h(hashCode) = hashCode & (N – 1);
```
而第二函数的性能明显要远优于第一个，然后由于采用2^N作为散列表的大小，当两个对象的hashCode的低位相同，很可能导致hashCode & (N – 1)相同，例如：
```
0101 0000 0000 1111 = 20495
0111 0000 0000 1111 = 28687
假如N是16，20495&(16-1) = 15, 28687&(16-1)=15, 造成了散列碰撞。
```
为了弥补hashCode的缺陷，我们需要引入一个`supplementalHash(int hashCode)` 函数，让原来hashCode的32个二进制都重新参与到散列的计算中来，例如：
```Java
private static int supplementalHash(int h) {
    h ^= (h >>> 20) ^ (h >>> 12);
    returnh ^ (h >>> 7) ^ (h >>> 4);
}
```
因此，最终的散列函数为：
```Java
h(hashCode) = supplementalHash(hashCode) & (N-1);  -- N是the power of 2
```

##11.3 处理散列碰撞

##11.4 HashMap实现
```Java
package io.cokepluscarbon.collection;

import java.util.HashSet;
import java.util.Set;
import java.util.LinkedList;

public class MyHashMap<K, V> implements MyMap<K, V> {
	private static int DEFAULT_INITAL_CAPACITY = 4;
	private static int MAXIMUM_CAPACIT = 1 << 30; // 2^30
	private int capacity;
	private static float DEFAULT_MAX_LOAD_FACTOR = 0.75f;
	private float loadFactorThreshold;
	private LinkedList<Entry<K, V>>[] table;
	private int size;

	public MyHashMap() {
		this(DEFAULT_INITAL_CAPACITY, DEFAULT_MAX_LOAD_FACTOR);
	}

	public MyHashMap(int capacity) {
		this(capacity, DEFAULT_MAX_LOAD_FACTOR);
	}

	@SuppressWarnings("unchecked")
	public MyHashMap(int capacity, float loadFactorThreshold) {
		if (capacity > MAXIMUM_CAPACIT) {
			this.capacity = MAXIMUM_CAPACIT;
		} else {
			this.capacity = trimToPowerOf2(capacity);
		}
		this.loadFactorThreshold = loadFactorThreshold;
		table = new LinkedList[capacity];
	}

	@Override
	public void clear() {
		size = 0;
		removeEntries();
	}

	@Override
	public boolean isEmpty() {
		return size() == 0;
	}

	@Override
	public boolean containsKey(K key) {
		return get(key) != null;
	}

	@Override
	public boolean containsValue(V value) {
		for (int i = 0; i < capacity; i++) {
			LinkedList<Entry<K, V>> bucket = table[i];

			if (bucket != null) {
				for (Entry<K, V> entry : bucket) {
					if (entry.getValue().equals(value)) {
						return true;
					}
				}
			}
		}

		return false;
	}

	@Override
	public Set<Entry<K, V>> entrySet() {
		Set<Entry<K, V>> set = new HashSet<Entry<K, V>>();

		for (int i = 0; i < capacity; i++) {
			LinkedList<Entry<K, V>> bucket = table[i];

			if (bucket != null) {
				for (Entry<K, V> entry : bucket) {
					set.add(entry);
				}
			}
		}

		return set;
	}

	@Override
	public Set<K> keySet() {
		Set<K> set = new HashSet<K>();

		for (int i = 0; i < capacity; i++) {
			LinkedList<Entry<K, V>> bucket = table[i];

			if (bucket != null) {
				for (Entry<K, V> entry : bucket) {
					set.add(entry.getKey());
				}
			}
		}

		return set;
	}

	@Override
	public V put(K key, V value) {
		// The key is already in the map
		if (get(key) != null) {
			int bucketIndex = hash(key.hashCode());
			LinkedList<Entry<K, V>> bucket = table[bucketIndex];
			for (Entry<K, V> entry : bucket) {
				if (entry.getKey().equals(key)) {
					entry.value = value;
					return value;
				}
			}
		}

		// Check load factor
		if (size > capacity * loadFactorThreshold) {
			if (capacity == MAXIMUM_CAPACIT) {
				throw new RuntimeException("Exceeding maximum capacity");
			}

			rehash();
		}

		// Insert if
		int bucketIndex = hash(key.hashCode());
		if (table[bucketIndex] == null) {
			table[bucketIndex] = new LinkedList<Entry<K, V>>();
		}
		table[bucketIndex].add(new Entry<K, V>(key, value));

		size++;

		return value;
	}

	@Override
	public void remove(K key) {
		int bucketIndex = hash(key.hashCode());
		LinkedList<Entry<K, V>> bucket = table[bucketIndex];
		for (Entry<K, V> entry : bucket) {
			if (entry.getKey().equals(key)) {
				bucket.remove(entry);
				size--;
				return;
			}
		}
	}

	@Override
	public int size() {
		return size;
	}

	@Override
	public V get(K key) {
		int bucketIndex = hash(key.hashCode());

		LinkedList<Entry<K, V>> bucket = table[bucketIndex];
		if (bucket != null) {
			for (Entry<K, V> entry : bucket) {
				if (entry.getKey().equals(key)) {
					return entry.getValue();
				}
			}
		}

		return null;
	}

	@Override
	public Set<V> values() {
		Set<V> set = new HashSet<V>();

		for (int i = 0; i < capacity; i++) {
			LinkedList<Entry<K, V>> bucket = table[i];

			if (bucket != null) {
				for (Entry<K, V> entry : bucket) {
					set.add(entry.getValue());
				}
			}
		}

		return set;
	}

	private int trimToPowerOf2(int initialCapacity) {
		int capacity = 1;
		while (capacity < initialCapacity) {
			capacity <<= 1;// Same as capacity *= 2. <= is more efficient
		}

		return capacity;
	}

	private int hash(int hashCode) {
		return supplementalHash(hashCode) & (capacity - 1);
	}

	private int supplementalHash(int hashCode) {
		hashCode ^= (hashCode >>> 20) ^ (hashCode >>> 12);
		return hashCode ^ (hashCode >>> 7) ^ (hashCode >>> 4);
	}

	private void removeEntries() {
		for (int i = 0; i < capacity; i++) {
			if (table[i] != null) {
				table[i].clear();
			}
		}
	}

	@SuppressWarnings("unchecked")
	private void rehash() {
		Set<Entry<K, V>> set = entrySet();
		capacity <<= 1;
		table = new LinkedList[capacity];
		size = 0;

		for (Entry<K, V> entry : set) {
			put(entry.getKey(), entry.getValue());
		}
	}

	@Override
	public String toString() {
		StringBuilder builder = new StringBuilder("[");

		for (int i = 0; i < capacity; i++) {
			if (table[i] != null && table[i].size() > 0)
				for (Entry<K, V> entry : table[i])
					builder.append(entry);
		}

		builder.append("]");
		return builder.toString();
	}
}
```

